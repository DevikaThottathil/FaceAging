{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWbbEkCIXPiL",
        "outputId": "048713e1-8a31-4b33-89fb-a8eadaf2fd3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy5rsAbj0liw",
        "outputId": "4d43550d-17e6-4c26-8fcd-ee52685de9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.2.0.post0-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.9/800.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.9.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.10.1 pytorch-lightning-2.2.0.post0 torchmetrics-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbaqXpFwXPiM"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import Trainer\n",
        "import itertools\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "IMG_EXTENSIONS = [\"png\", \"jpg\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_wNSrpKXPiM"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/FaceAging/archive.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/drive/MyDrive/FaceAging/archive\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYLaKMyDXPiM"
      },
      "outputs": [],
      "source": [
        "# pip install pytorch-lightning==1.5.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3QVb60-XPiM",
        "outputId": "3501909a-e399-427b-83c3-7d5dd025a2da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images found: 23708\n",
            "Image in A: 7134 and B: 7134\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "inp_dir=\"/content/drive/MyDrive/FaceAging/archive/UTKFace\"\n",
        "out_dir=\"/content/drive/MyDrive/FaceAging/archive/processed\"\n",
        "\n",
        "\n",
        "image_names = [x for x in os.listdir(inp_dir) if x.endswith('.jpg')]\n",
        "print(f\"Total images found: {len(image_names)}\")\n",
        "\n",
        "ages = [int(x.split('_')[0]) for x in image_names]\n",
        "\n",
        "ages_to_keep_a = [x for x in range(18, 29)]\n",
        "ages_to_keep_b = [x for x in range(40, 120)]\n",
        "\n",
        "domainA, domainB = [], []\n",
        "for image_name, age in zip(image_names, ages):\n",
        "    if age in ages_to_keep_a:\n",
        "        domainA.append(image_name)\n",
        "    elif age in ages_to_keep_b:\n",
        "        domainB.append(image_name)\n",
        "\n",
        "N = min(len(domainA), len(domainB))\n",
        "domainA = domainA[:N]\n",
        "domainB = domainB[:N]\n",
        "\n",
        "print(f\"Image in A: {len(domainA)} and B: {len(domainB)}\")\n",
        "\n",
        "domainA_dir = os.path.join(out_dir, 'trainA')\n",
        "domainB_dir = os.path.join(out_dir, 'trainB')\n",
        "\n",
        "os.makedirs(domainA_dir, exist_ok=True)\n",
        "os.makedirs(domainB_dir, exist_ok=True)\n",
        "\n",
        "for imageA, imageB in zip(domainA, domainB):\n",
        "    shutil.copy(os.path.join(inp_dir, imageA), os.path.join(domainA_dir, imageA))\n",
        "    shutil.copy(os.path.join(inp_dir, imageB), os.path.join(domainB_dir, imageB))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrZKrYlDXPiM"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        conv_block = [nn.ReflectionPad2d(1),\n",
        "                      nn.Conv2d(in_features, in_features, 3),\n",
        "                      nn.BatchNorm2d(in_features),\n",
        "                      nn.ReLU(),\n",
        "                      nn.ReflectionPad2d(1),\n",
        "                      nn.Conv2d(in_features, in_features, 3),\n",
        "                      nn.BatchNorm2d(in_features)]\n",
        "\n",
        "        self.conv_block = nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngf, n_residual_blocks=9):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Initial convolution block\n",
        "        model = [nn.ReflectionPad2d(3),\n",
        "                 nn.Conv2d(3, ngf, 7),\n",
        "                 nn.BatchNorm2d(ngf),\n",
        "                 nn.ReLU()]\n",
        "\n",
        "        # Downsampling\n",
        "        in_features = ngf\n",
        "        out_features = in_features * 2\n",
        "        for _ in range(2):\n",
        "            model += [nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                      nn.BatchNorm2d(out_features),\n",
        "                      nn.ReLU()]\n",
        "            in_features = out_features\n",
        "            out_features = in_features * 2\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(n_residual_blocks):\n",
        "            model += [ResidualBlock(in_features)]\n",
        "\n",
        "        # Upsampling\n",
        "        out_features = in_features // 2\n",
        "        for _ in range(2):\n",
        "            model += [nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
        "                      nn.BatchNorm2d(out_features),\n",
        "                      nn.ReLU()]\n",
        "            in_features = out_features\n",
        "            out_features = in_features // 2\n",
        "\n",
        "        # Output layer\n",
        "        model += [nn.ReflectionPad2d(3),\n",
        "                  nn.Conv2d(ngf, 3, 7),\n",
        "                  nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # A bunch of convolutions one after another\n",
        "        model = [nn.Conv2d(3, ndf, 4, stride=2, padding=1),\n",
        "                 nn.LeakyReLU(0.2, inplace=True)]\n",
        "\n",
        "        model += [nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1),\n",
        "                  nn.BatchNorm2d(ndf * 2),\n",
        "                  nn.LeakyReLU(0.2, inplace=True)]\n",
        "\n",
        "        model += [nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1),\n",
        "                  nn.InstanceNorm2d(ndf * 4),\n",
        "                  nn.LeakyReLU(0.2, inplace=True)]\n",
        "\n",
        "        model += [nn.Conv2d(ndf * 4, ndf * 8, 4, padding=1),\n",
        "                  nn.InstanceNorm2d(ndf * 8),\n",
        "                  nn.LeakyReLU(0.2, inplace=True)]\n",
        "\n",
        "        # FCN classification layer\n",
        "        model += [nn.Conv2d(ndf * 8, 1, 4, padding=1)]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        # Average pooling and flatten\n",
        "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}