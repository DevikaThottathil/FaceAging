{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPQDuqTcTNeA",
        "outputId": "922e3225-6f1a-4c59-a6a5-05e949b0ed9a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/transformers/gan/archive.zip\", 'r')\n",
        "# zip_ref.extractall(\"/content/drive/MyDrive/transformers/gan/archive\")\n",
        "# zip_ref.close()"
      ],
      "metadata": {
        "id": "P2a7VetbTVi2"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pytorch-lightning==1.5.10"
      ],
      "metadata": {
        "id": "ScQjb9J6TuYw"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# inp_dir=\"/content/drive/MyDrive/transformers/gan/archive/UTKFace\"\n",
        "# out_dir=\"/content/drive/MyDrive/transformers/gan/processed\"\n",
        "\n",
        "\n",
        "# image_names = [x for x in os.listdir(inp_dir) if x.endswith('.jpg')]\n",
        "# print(f\"Total images found: {len(image_names)}\")\n",
        "\n",
        "# ages = [int(x.split('_')[0]) for x in image_names]\n",
        "\n",
        "# ages_to_keep_a = [x for x in range(18, 29)]\n",
        "# ages_to_keep_b = [x for x in range(40, 120)]\n",
        "\n",
        "# domainA, domainB = [], []\n",
        "# for image_name, age in zip(image_names, ages):\n",
        "#     if age in ages_to_keep_a:\n",
        "#         domainA.append(image_name)\n",
        "#     elif age in ages_to_keep_b:\n",
        "#         domainB.append(image_name)\n",
        "\n",
        "# N = min(len(domainA), len(domainB))\n",
        "# domainA = domainA[:N]\n",
        "# domainB = domainB[:N]\n",
        "\n",
        "# print(f\"Image in A: {len(domainA)} and B: {len(domainB)}\")\n",
        "\n",
        "# domainA_dir = os.path.join(out_dir, 'trainA')\n",
        "# domainB_dir = os.path.join(out_dir, 'trainB')\n",
        "\n",
        "# os.makedirs(domainA_dir, exist_ok=True)\n",
        "# os.makedirs(domainB_dir, exist_ok=True)\n",
        "\n",
        "# for imageA, imageB in zip(domainA, domainB):\n",
        "#     shutil.copy(os.path.join(inp_dir, imageA), os.path.join(domainA_dir, imageA))\n",
        "#     shutil.copy(os.path.join(inp_dir, imageB), os.path.join(domainB_dir, imageB))\n"
      ],
      "metadata": {
        "id": "8Rx_KpK4WgPu"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "L_3-NN3iTBwr"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import Trainer\n",
        "import itertools\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "IMG_EXTENSIONS = [\"png\", \"jpg\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "gGQCd2yCTBwx"
      },
      "outputs": [],
      "source": [
        "class ImagetoImageDataset(Dataset):\n",
        "    def __init__(self, domainA_dir, domainB_dir, transforms=None):\n",
        "        self.imagesA = [os.path.join(domainA_dir, x) for x in os.listdir(domainA_dir) if\n",
        "                        x.lower().endswith(tuple(IMG_EXTENSIONS))]\n",
        "        self.imagesB = [os.path.join(domainB_dir, x) for x in os.listdir(domainB_dir) if\n",
        "                        x.lower().endswith(tuple(IMG_EXTENSIONS))]\n",
        "\n",
        "        self.transforms = transforms\n",
        "        self.lenA = len(self.imagesA)\n",
        "        self.lenB = len(self.imagesB)\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(self.lenA, self.lenB)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        idx_a = idx_b = idx\n",
        "        if idx_a >= self.lenA:\n",
        "            idx_a = np.random.randint(self.lenA)\n",
        "        if idx_b >= self.lenB:\n",
        "            idx_b = np.random.randint(self.lenB)\n",
        "\n",
        "        imageA = np.array(Image.open(self.imagesA[idx_a]).convert(\"RGB\"))\n",
        "        imageB = np.array(Image.open(self.imagesB[idx_b]).convert(\"RGB\"))\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            imageA = self.transforms(imageA)\n",
        "            imageB = self.transforms(imageB)\n",
        "\n",
        "        return imageA, imageB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "s3FhC1bTTBwz"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        conv_block = [nn.ReflectionPad2d(1),\n",
        "                      nn.Conv2d(in_features, in_features, 3),\n",
        "                      nn.BatchNorm2d(in_features),\n",
        "                      nn.ReLU(),\n",
        "                      nn.ReflectionPad2d(1),\n",
        "                      nn.Conv2d(in_features, in_features, 3),\n",
        "                      nn.BatchNorm2d(in_features)]\n",
        "\n",
        "        self.conv_block = nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngf, n_residual_blocks=9):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Initial convolution block\n",
        "        model = [nn.ReflectionPad2d(3),\n",
        "                 nn.Conv2d(3, ngf, 7),\n",
        "                 nn.BatchNorm2d(ngf),\n",
        "                 nn.ReLU()]\n",
        "\n",
        "        # Downsampling\n",
        "        in_features = ngf\n",
        "        out_features = in_features * 2\n",
        "        for _ in range(2):\n",
        "            model += [nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                      nn.BatchNorm2d(out_features),\n",
        "                      nn.ReLU()]\n",
        "            in_features = out_features\n",
        "            out_features = in_features * 2\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(n_residual_blocks):\n",
        "            model += [ResidualBlock(in_features)]\n",
        "\n",
        "        # Upsampling\n",
        "        out_features = in_features // 2\n",
        "        for _ in range(2):\n",
        "            model += [nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
        "                      nn.BatchNorm2d(out_features),\n",
        "                      nn.ReLU()]\n",
        "            in_features = out_features\n",
        "            out_features = in_features // 2\n",
        "\n",
        "        # Output layer\n",
        "        model += [nn.ReflectionPad2d(3),\n",
        "                  nn.Conv2d(ngf, 3, 7),\n",
        "                  nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # A bunch of convolutions one after another\n",
        "        model = [nn.Conv2d(3, ndf, 4, stride=2, padding=1),\n",
        "                 nn.LeakyReLU(0.2, inplace=True)]\n",
        "\n",
        "        model += [nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1),\n",
        "                  nn.BatchNorm2d(ndf * 2),\n",
        "                  nn.LeakyReLU(0.2, inplace=True)]\n",
        "\n",
        "        model += [nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1),\n",
        "                  nn.InstanceNorm2d(ndf * 4),\n",
        "                  nn.LeakyReLU(0.2, inplace=True)]\n",
        "\n",
        "        model += [nn.Conv2d(ndf * 4, ndf * 8, 4, padding=1),\n",
        "                  nn.InstanceNorm2d(ndf * 8),\n",
        "                  nn.LeakyReLU(0.2, inplace=True)]\n",
        "\n",
        "        # FCN classification layer\n",
        "        model += [nn.Conv2d(ndf * 8, 1, 4, padding=1)]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        # Average pooling and flatten\n",
        "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "SuVDkrgoTBw0"
      },
      "outputs": [],
      "source": [
        "class AgingGAN(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super(AgingGAN, self).__init__()\n",
        "        self.save_hyperparameters(hparams)\n",
        "        self.genA2B = Generator(hparams['ngf'], n_residual_blocks=hparams['n_blocks'])\n",
        "        self.genB2A = Generator(hparams['ngf'], n_residual_blocks=hparams['n_blocks'])\n",
        "        self.disGA = Discriminator(hparams['ndf'])\n",
        "        self.disGB = Discriminator(hparams['ndf'])\n",
        "\n",
        "        # cache for generated images\n",
        "        self.generated_A = None\n",
        "        self.generated_B = None\n",
        "        self.real_A = None\n",
        "        self.real_B = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.genA2B(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        real_A, real_B = batch\n",
        "\n",
        "        if optimizer_idx == 0:\n",
        "            # Identity loss\n",
        "            # G_A2B(B) should equal B if real B is fed\n",
        "            same_B = self.genA2B(real_B)\n",
        "            loss_identity_B = F.l1_loss(same_B, real_B) * self.hparams['identity_weight']\n",
        "            # G_B2A(A) should equal A if real A is fed\n",
        "            same_A = self.genB2A(real_A)\n",
        "            loss_identity_A = F.l1_loss(same_A, real_A) * self.hparams['identity_weight']\n",
        "\n",
        "            # GAN loss\n",
        "            fake_B = self.genA2B(real_A)\n",
        "            pred_fake = self.disGB(fake_B)\n",
        "            loss_GAN_A2B = F.mse_loss(pred_fake, torch.ones(pred_fake.shape).type_as(pred_fake)) * self.hparams[\n",
        "                'adv_weight']\n",
        "\n",
        "            fake_A = self.genB2A(real_B)\n",
        "            pred_fake = self.disGA(fake_A)\n",
        "            loss_GAN_B2A = F.mse_loss(pred_fake, torch.ones(pred_fake.shape).type_as(pred_fake)) * self.hparams[\n",
        "                'adv_weight']\n",
        "\n",
        "            # Cycle loss\n",
        "            recovered_A = self.genB2A(fake_B)\n",
        "            loss_cycle_ABA = F.l1_loss(recovered_A, real_A) * self.hparams['cycle_weight']\n",
        "\n",
        "            recovered_B = self.genA2B(fake_A)\n",
        "            loss_cycle_BAB = F.l1_loss(recovered_B, real_B) * self.hparams['cycle_weight']\n",
        "\n",
        "            # Total loss\n",
        "            g_loss = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
        "\n",
        "            output = {\n",
        "                'loss': g_loss,\n",
        "                'log': {'Loss/Generator': g_loss}\n",
        "            }\n",
        "            self.log('Loss/Generator', g_loss)\n",
        "\n",
        "            self.generated_B = fake_B\n",
        "            self.generated_A = fake_A\n",
        "\n",
        "            self.real_B = real_B\n",
        "            self.real_A = real_A\n",
        "\n",
        "            # Log to tb\n",
        "            if batch_idx % 500 == 0:\n",
        "                self.genA2B.eval()\n",
        "                self.genB2A.eval()\n",
        "                fake_A = self.genB2A(real_B)\n",
        "                fake_B = self.genA2B(real_A)\n",
        "                self.logger.experiment.add_image('Real/A', make_grid(self.real_A, normalize=True, scale_each=True),\n",
        "                                                 self.current_epoch)\n",
        "                self.logger.experiment.add_image('Real/B', make_grid(self.real_B, normalize=True, scale_each=True),\n",
        "                                                 self.current_epoch)\n",
        "                self.logger.experiment.add_image('Generated/A',\n",
        "                                                 make_grid(self.generated_A, normalize=True, scale_each=True),\n",
        "                                                 self.current_epoch)\n",
        "                self.logger.experiment.add_image('Generated/B',\n",
        "                                                 make_grid(self.generated_B, normalize=True, scale_each=True),\n",
        "                                                 self.current_epoch)\n",
        "                self.genA2B.train()\n",
        "                self.genB2A.train()\n",
        "            return output\n",
        "\n",
        "        if optimizer_idx == 1:\n",
        "            # Real loss\n",
        "            pred_real = self.disGA(real_A)\n",
        "            loss_D_real = F.mse_loss(pred_real, torch.ones(pred_real.shape).type_as(pred_real))\n",
        "\n",
        "            # Fake loss\n",
        "            fake_A = self.generated_A\n",
        "            pred_fake = self.disGA(fake_A.detach())\n",
        "            loss_D_fake = F.mse_loss(pred_fake, torch.zeros(pred_fake.shape).type_as(pred_fake))\n",
        "\n",
        "            # Total loss\n",
        "            loss_D_A = (loss_D_real + loss_D_fake) * 0.5\n",
        "\n",
        "            # Real loss\n",
        "            pred_real = self.disGB(real_B)\n",
        "            loss_D_real = F.mse_loss(pred_real, torch.ones(pred_real.shape).type_as(pred_real))\n",
        "\n",
        "            # Fake loss\n",
        "            fake_B = self.generated_B\n",
        "            pred_fake = self.disGB(fake_B.detach())\n",
        "            loss_D_fake = F.mse_loss(pred_fake, torch.zeros(pred_fake.shape).type_as(pred_fake))\n",
        "\n",
        "            # Total loss\n",
        "            loss_D_B = (loss_D_real + loss_D_fake) * 0.5\n",
        "            d_loss = loss_D_A + loss_D_B\n",
        "            output = {\n",
        "                'loss': d_loss,\n",
        "                'log': {'Loss/Discriminator': d_loss}\n",
        "            }\n",
        "            self.log('Loss/Discriminator', d_loss)\n",
        "\n",
        "            return output\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        g_optim = torch.optim.Adam(itertools.chain(self.genA2B.parameters(), self.genB2A.parameters()),\n",
        "                                   lr=self.hparams['lr'], betas=(0.5, 0.999),\n",
        "                                   weight_decay=self.hparams['weight_decay'])\n",
        "        d_optim = torch.optim.Adam(itertools.chain(self.disGA.parameters(),\n",
        "                                                   self.disGB.parameters()),\n",
        "                                   lr=self.hparams['lr'],\n",
        "                                   betas=(0.5, 0.999),\n",
        "                                   weight_decay=self.hparams['weight_decay'])\n",
        "        return [g_optim, d_optim], []\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize((self.hparams['img_size'] + 50, self.hparams['img_size'] + 50)),\n",
        "            transforms.RandomCrop(self.hparams['img_size']),\n",
        "            #transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),\n",
        "            #transforms.RandomPerspective(p=0.5),\n",
        "            transforms.RandomRotation(degrees=(0, int(self.hparams['augment_rotation']))),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "        ])\n",
        "        dataset = ImagetoImageDataset(self.hparams['domainA_dir'], self.hparams['domainB_dir'], train_transform)\n",
        "        return DataLoader(dataset,\n",
        "                          batch_size=self.hparams['batch_size'],\n",
        "                          num_workers=self.hparams['num_workers'],\n",
        "                          shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "cZdQam4ETBw2"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.config = {\n",
        "            'domainA_dir': '/content/drive/MyDrive/transformers/gan/processed/trainA',\n",
        "            'domainB_dir': '/content/drive/MyDrive/transformers/gan/processed/trainB',\n",
        "            'ngf': 32,\n",
        "            'ndf': 32,\n",
        "            'n_blocks': 9,\n",
        "            'adv_weight': 2,\n",
        "            'cycle_weight': 10,\n",
        "            'identity_weight': 7,\n",
        "            'lr': 0.0001,\n",
        "            'weight_decay': 0.0001,\n",
        "            'img_size': 256,\n",
        "            'batch_size': 3,\n",
        "            'num_workers': 12,\n",
        "            'epochs': 100,\n",
        "            'augment_rotation': 80,\n",
        "            'gpus': 1\n",
        "        }\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return self.config[key]\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        self.config[key] = value\n",
        "\n",
        "    def to_dict(self):\n",
        "        return self.config\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "jKDg_q_tTBw3"
      },
      "outputs": [],
      "source": [
        "config=config.to_dict()\n",
        "model = AgingGAN(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381,
          "referenced_widgets": [
            "647c0b8b2ffb44f0abb78ee0fc4d0abd",
            "f25a3a8be7ed4c88960050a83ce8607a",
            "4f073e02058d4024b11e1574d2acfb21",
            "92bf7f83d6a849199565a7705f663681",
            "eb72a4119dc74564a542489c3e9b0f4b",
            "68b954903cce4334b59c56ab3927422d",
            "4b8102385920422ab3844549137bd1e3",
            "7a251ee7417d40919d04bffcf5cd4eeb",
            "f4b7f9e05e584532a63f4c49cf953a4d",
            "9603d3cdb7f64b92984954846050ef9d",
            "098bd25bdfb243dfa3f4ab8f1fc98ede"
          ]
        },
        "id": "bRzvGHiyTBw4",
        "outputId": "99f983dc-a408-465d-cbfa-ee74f688104c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.distributed:GPU available: True, used: True\n",
            "INFO:pytorch_lightning.utilities.distributed:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.distributed:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name   | Type          | Params\n",
            "-----------------------------------------\n",
            "0 | genA2B | Generator     | 2.9 M \n",
            "1 | genB2A | Generator     | 2.9 M \n",
            "2 | disGA  | Discriminator | 694 K \n",
            "3 | disGB  | Discriminator | 694 K \n",
            "-----------------------------------------\n",
            "7.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "7.1 M     Total params\n",
            "28.401    Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "647c0b8b2ffb44f0abb78ee0fc4d0abd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer = Trainer(max_epochs=config['epochs'], gpus=config['gpus'], auto_scale_batch_size='binsearch')\n",
        "trainer.fit(model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "647c0b8b2ffb44f0abb78ee0fc4d0abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f25a3a8be7ed4c88960050a83ce8607a",
              "IPY_MODEL_4f073e02058d4024b11e1574d2acfb21",
              "IPY_MODEL_92bf7f83d6a849199565a7705f663681"
            ],
            "layout": "IPY_MODEL_eb72a4119dc74564a542489c3e9b0f4b"
          }
        },
        "f25a3a8be7ed4c88960050a83ce8607a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68b954903cce4334b59c56ab3927422d",
            "placeholder": "​",
            "style": "IPY_MODEL_4b8102385920422ab3844549137bd1e3",
            "value": "Epoch 0:   1%"
          }
        },
        "4f073e02058d4024b11e1574d2acfb21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a251ee7417d40919d04bffcf5cd4eeb",
            "max": 2378,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4b7f9e05e584532a63f4c49cf953a4d",
            "value": 20
          }
        },
        "92bf7f83d6a849199565a7705f663681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9603d3cdb7f64b92984954846050ef9d",
            "placeholder": "​",
            "style": "IPY_MODEL_098bd25bdfb243dfa3f4ab8f1fc98ede",
            "value": " 20/2378 [00:15&lt;29:58,  1.31it/s, loss=4.77, v_num=3]"
          }
        },
        "eb72a4119dc74564a542489c3e9b0f4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "68b954903cce4334b59c56ab3927422d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b8102385920422ab3844549137bd1e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a251ee7417d40919d04bffcf5cd4eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b7f9e05e584532a63f4c49cf953a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9603d3cdb7f64b92984954846050ef9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "098bd25bdfb243dfa3f4ab8f1fc98ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}